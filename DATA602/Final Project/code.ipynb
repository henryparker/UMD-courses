{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import numpy as np\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process and reorganize dataset files.\n",
    "    # INPUT: \n",
    "    #   filename: The root directory path of the original dataset\n",
    "    #   datasetname: The target directory path where processed files will be stored\n",
    "    # OUTPUT:\n",
    "    #   Organizes and stores the processed files in the target directory, removing the first 4 lines from each file.\n",
    "def file_iniate(filename, datasetname):\n",
    "\tdataset = filename\n",
    "\tfor group in tqdm(os.listdir(dataset)):\n",
    "\t\tfilepath = os.path.join(dataset, group)\n",
    "\t\tfiles = os.listdir(filepath)\n",
    "\t\tfor file in files:\n",
    "\t\t\twith open(os.path.join(filepath, file), 'rb',) as f:\n",
    "\t\t\t\tlines=f.readlines()[4:]\n",
    "\t\n",
    "\t\t\tfolder = os.path.join(datasetname, group)\n",
    "\t\t\tif not os.path.exists(folder):\n",
    "\t\t\t\tos.makedirs(folder)\n",
    "\n",
    "\t\t\twith open(os.path.join(folder, file), 'wb') as f:\n",
    "\t\t\t\tf.writelines(lines)\n",
    "\t\t\t\n",
    "# Stratified Kfold Implement: Ensure that the proportion of categories in each fold is equal to \n",
    "#                             the proportion of categories in the original data source set\n",
    "    # INPUT: \n",
    "    #   X: a list of data\n",
    "    #   y: a list of labels\n",
    "    #   k: kfold\n",
    "    #   random_seed: fix randomness\n",
    "    # OUTPUT: \n",
    "    #   yield a iterable generator, containing train indices and valid/test indices\n",
    "def stratified_kfold(X, y, k=5, random_seed=None):\n",
    "\tif random_seed is not None:\n",
    "\t\tnp.random.seed(random_seed)\n",
    "\t\n",
    "\t_, class_indices = np.unique(y, return_inverse=True)\n",
    "\tclass_counts = defaultdict(list)\n",
    "\t\n",
    "\tfor idx, class_idx in enumerate(class_indices):\n",
    "\t\tclass_counts[class_idx].append(idx)\n",
    "\n",
    "\tfolds = [[] for _ in range(k)]\n",
    "\t\n",
    "\tfor class_idx, indices in class_counts.items():\n",
    "\t\tnp.random.shuffle(indices)\n",
    "\t\t\n",
    "\t\tfor i, idx in enumerate(indices):\n",
    "\t\t\tfolds[i % k].append(idx)\n",
    "\n",
    "\tfor i in range(k):\n",
    "\t\ttest_indices = folds[i]\n",
    "\t\ttrain_indices = [idx for j in range(k) if j != i for idx in folds[j]]\n",
    "\t\tyield train_indices, test_indices\n",
    "\t\t\n",
    "# Function to process a file and extract a list of words after cleaning.\n",
    "def file2wordlist(filename):\n",
    "\twith open(filename, 'rb') as f:\n",
    "\t\tlines = f.readlines()\n",
    "\t\t\n",
    "\tstring_lines = [line.decode('utf-8', errors='ignore').strip() for line in lines]\n",
    "\tcleaned_lines = [re.sub(r'[^a-zA-Z\\s]', ' ', line.replace(\"'s\", \"\")) for line in string_lines]\n",
    "\tresult_string = ' '.join(cleaned_lines)\n",
    "\twords = re.findall(r'\\b[a-zA-Z]+\\b', result_string)\n",
    "\n",
    "\twords = list(map(lambda x: x.lower(), words))\n",
    "\treturn words\n",
    "\n",
    "# Function to count the frequency of words in a list of files.\n",
    "def wordcount(files):\n",
    "\twords = []\n",
    "\tfor f in tqdm(files):\n",
    "\t\twords.append(file2wordlist(f))\n",
    "\treturn Counter([item for sublist in words for item in sublist]), words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:05<00:00,  3.77it/s]\n"
     ]
    }
   ],
   "source": [
    "# Call file_iniate function to process data from '20_newsgroups' to 'dataset', deleting first 4 lines and cleaning\n",
    "files, dataset = '20_newsgroups', 'dataset'\n",
    "file_iniate(files, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data (file directory) and labels\n",
    "data = []\n",
    "labels = []\n",
    "for i, group in enumerate(os.listdir(dataset)):\n",
    "    filepath = os.path.join(dataset, group)\n",
    "    files = os.listdir(filepath)\n",
    "    data.extend([os.path.join(filepath, f) for f in files])\n",
    "    labels.extend([i for _ in range(len(files))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute the Term Frequency (TF) of terms in a document.\n",
    "def compute_tf(document_tokens):\n",
    "    term_count = Counter(document_tokens)\n",
    "    total_terms = len(document_tokens)\n",
    "    return {term: count / total_terms for term, count in term_count.items()}\n",
    "\n",
    "# Function to compute the Inverse Document Frequency (IDF) of terms in a corpus.\n",
    "def compute_idf(corpus_tokens):\n",
    "    num_documents = len(corpus_tokens)\n",
    "    idf = {}\n",
    "    for document_tokens in corpus_tokens:\n",
    "        for term in set(document_tokens):\n",
    "            idf[term] = idf.get(term, 0) + 1\n",
    "    return {term: np.log((num_documents + 1) / (1 + doc_count)) + 1 for term, doc_count in idf.items()}\n",
    "\n",
    "# Function to compute the Term Frequency-Inverse Document Frequency (TF-IDF) for each document in the corpus.\n",
    "def compute_tfidf(corpus_tokens):\n",
    "    idf = compute_idf(corpus_tokens)\n",
    "    tfidf_vectors = []\n",
    "    for document_tokens in corpus_tokens:\n",
    "        tf = compute_tf(document_tokens)\n",
    "        tfidf_vectors.append({term: tf[term] * idf[term] for term in tf})\n",
    "    return tfidf_vectors, idf\n",
    "\n",
    "# Function to convert a list of TF-IDF vectors into a sparse matrix representation.\n",
    "# This function uses the Compressed Sparse Row format to store the document-term matrix efficiently.\n",
    "def vectorize(tfidf_vectors, idf):\n",
    "    vocab = list(idf.keys())\n",
    "    term_index = {term: idx for idx, term in enumerate(vocab)}\n",
    "\n",
    "    num_docs = len(tfidf_vectors)\n",
    "    num_terms = len(vocab)\n",
    "    rows = []\n",
    "    cols = []\n",
    "    values = []\n",
    "\n",
    "    for doc_idx, tfidf in enumerate(tfidf_vectors):\n",
    "        for term, value in tfidf.items():\n",
    "            if term in term_index:\n",
    "                rows.append(doc_idx)\n",
    "                cols.append(term_index[term])\n",
    "                values.append(value)\n",
    "    \n",
    "    vectors = csr_matrix((values, (rows, cols)), shape=(num_docs, num_terms))\n",
    "    return vectors\n",
    "\n",
    "# Function to convert a list of documents into their vector representations. \n",
    "# idf is for vocabulary, necessary for Test set.\n",
    "def doc2vec(documents, idf=None):\n",
    "    if not idf:\n",
    "        tfidf_vectors, idf = compute_tfidf(documents)\n",
    "    else:\n",
    "        tfidf_vectors, _ = compute_tfidf(documents)\n",
    "    X = vectorize(tfidf_vectors, idf)\n",
    "    return X, idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------1th fold--------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15997/15997 [00:55<00:00, 289.62it/s]\n",
      "100%|██████████| 4000/4000 [00:13<00:00, 300.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.77      0.78       202\n",
      "           1       0.83      0.86      0.85       195\n",
      "           2       0.86      0.79      0.83       218\n",
      "           3       0.77      0.85      0.81       182\n",
      "           4       0.88      0.91      0.90       193\n",
      "           5       0.88      0.92      0.90       191\n",
      "           6       0.88      0.89      0.89       197\n",
      "           7       0.94      0.88      0.91       214\n",
      "           8       0.97      0.97      0.97       200\n",
      "           9       0.96      0.96      0.96       199\n",
      "          10       0.97      0.97      0.97       202\n",
      "          11       0.97      0.97      0.97       202\n",
      "          12       0.85      0.88      0.87       194\n",
      "          13       0.97      0.96      0.96       203\n",
      "          14       0.96      0.96      0.96       201\n",
      "          15       0.99      0.98      0.99       204\n",
      "          16       0.93      0.87      0.90       212\n",
      "          17       0.95      0.91      0.93       209\n",
      "          18       0.74      0.75      0.75       198\n",
      "          19       0.57      0.62      0.59       184\n",
      "\n",
      "    accuracy                           0.88      4000\n",
      "   macro avg       0.88      0.88      0.88      4000\n",
      "weighted avg       0.89      0.88      0.89      4000\n",
      "\n",
      "--------------2th fold--------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15997/15997 [00:02<00:00, 5421.62it/s]\n",
      "100%|██████████| 4000/4000 [00:00<00:00, 5528.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.81      0.78       186\n",
      "           1       0.89      0.86      0.87       208\n",
      "           2       0.80      0.88      0.84       182\n",
      "           3       0.83      0.82      0.83       204\n",
      "           4       0.91      0.88      0.90       206\n",
      "           5       0.92      0.90      0.91       203\n",
      "           6       0.81      0.83      0.82       197\n",
      "           7       0.91      0.92      0.92       197\n",
      "           8       0.96      0.93      0.94       207\n",
      "           9       0.95      0.98      0.97       194\n",
      "          10       0.98      0.96      0.97       204\n",
      "          11       0.98      0.98      0.98       202\n",
      "          12       0.84      0.88      0.86       192\n",
      "          13       0.97      0.97      0.97       202\n",
      "          14       0.95      0.95      0.95       200\n",
      "          15       1.00      0.97      0.99       206\n",
      "          16       0.92      0.86      0.89       215\n",
      "          17       0.96      0.92      0.94       209\n",
      "          18       0.74      0.82      0.78       180\n",
      "          19       0.65      0.63      0.64       206\n",
      "\n",
      "    accuracy                           0.89      4000\n",
      "   macro avg       0.89      0.89      0.89      4000\n",
      "weighted avg       0.89      0.89      0.89      4000\n",
      "\n",
      "--------------3th fold--------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15998/15998 [00:02<00:00, 5334.47it/s]\n",
      "100%|██████████| 3999/3999 [00:00<00:00, 5395.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.76      0.75       194\n",
      "           1       0.84      0.84      0.84       199\n",
      "           2       0.84      0.85      0.85       199\n",
      "           3       0.80      0.79      0.80       202\n",
      "           4       0.86      0.90      0.88       193\n",
      "           5       0.88      0.91      0.89       194\n",
      "           6       0.84      0.89      0.86       189\n",
      "           7       0.92      0.91      0.91       201\n",
      "           8       0.97      0.97      0.97       199\n",
      "           9       0.94      0.95      0.95       198\n",
      "          10       0.98      0.97      0.98       203\n",
      "          11       0.97      0.95      0.96       205\n",
      "          12       0.87      0.84      0.85       208\n",
      "          13       0.89      0.94      0.91       188\n",
      "          14       0.97      0.92      0.94       211\n",
      "          15       0.99      0.99      0.99       199\n",
      "          16       0.87      0.86      0.86       203\n",
      "          17       0.96      0.95      0.96       202\n",
      "          18       0.72      0.74      0.73       197\n",
      "          19       0.64      0.59      0.61       215\n",
      "\n",
      "    accuracy                           0.88      3999\n",
      "   macro avg       0.88      0.88      0.88      3999\n",
      "weighted avg       0.88      0.88      0.87      3999\n",
      "\n",
      "--------------4th fold--------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15998/15998 [00:03<00:00, 4955.64it/s]\n",
      "100%|██████████| 3999/3999 [00:00<00:00, 5663.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.75      0.75       201\n",
      "           1       0.83      0.85      0.84       195\n",
      "           2       0.77      0.82      0.80       187\n",
      "           3       0.82      0.78      0.80       211\n",
      "           4       0.89      0.92      0.90       194\n",
      "           5       0.90      0.89      0.89       202\n",
      "           6       0.83      0.84      0.83       198\n",
      "           7       0.91      0.96      0.94       189\n",
      "           8       0.97      0.96      0.96       203\n",
      "           9       0.95      0.95      0.95       200\n",
      "          10       0.97      0.98      0.98       198\n",
      "          11       0.97      0.97      0.97       201\n",
      "          12       0.93      0.89      0.91       209\n",
      "          13       0.95      0.94      0.95       202\n",
      "          14       0.95      0.95      0.95       200\n",
      "          15       1.00      0.97      0.99       205\n",
      "          16       0.89      0.89      0.89       200\n",
      "          17       0.94      0.89      0.92       212\n",
      "          18       0.73      0.75      0.74       194\n",
      "          19       0.57      0.58      0.58       198\n",
      "\n",
      "    accuracy                           0.88      3999\n",
      "   macro avg       0.88      0.88      0.88      3999\n",
      "weighted avg       0.88      0.88      0.88      3999\n",
      "\n",
      "--------------5th fold--------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15998/15998 [00:03<00:00, 4969.94it/s]\n",
      "100%|██████████| 3999/3999 [00:00<00:00, 4371.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.76      0.80       221\n",
      "           1       0.86      0.83      0.85       207\n",
      "           2       0.90      0.87      0.88       205\n",
      "           3       0.74      0.85      0.79       175\n",
      "           4       0.91      0.91      0.91       198\n",
      "           5       0.90      0.91      0.91       197\n",
      "           6       0.88      0.86      0.87       205\n",
      "           7       0.93      0.95      0.94       194\n",
      "           8       0.97      0.97      0.97       201\n",
      "           9       0.95      0.95      0.95       202\n",
      "          10       0.97      0.96      0.97       203\n",
      "          11       0.96      0.95      0.96       203\n",
      "          12       0.90      0.87      0.88       206\n",
      "          13       0.96      0.94      0.95       205\n",
      "          14       0.96      0.96      0.96       202\n",
      "          15       1.00      1.00      1.00       199\n",
      "          16       0.91      0.88      0.89       206\n",
      "          17       0.95      0.93      0.94       204\n",
      "          18       0.72      0.77      0.74       188\n",
      "          19       0.59      0.66      0.62       178\n",
      "\n",
      "    accuracy                           0.89      3999\n",
      "   macro avg       0.89      0.89      0.89      3999\n",
      "weighted avg       0.89      0.89      0.89      3999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "acc = []\n",
    "i = 1\n",
    "for train_idx, test_idx in stratified_kfold(data, labels, k=5, random_seed=42):\n",
    "    print(f'----------------------{i}th fold----------------------')\n",
    "    i += 1\n",
    "\n",
    "    train_files = [data[i] for i in train_idx]\n",
    "    train_labels = [labels[i] for i in train_idx]\n",
    "\n",
    "    # train set\n",
    "    wc, words = wordcount(train_files)\n",
    "    stop = set(i for i, _ in wc.most_common(300))\n",
    "    documents = [[i for i in sub if i not in stop] for sub in words]\n",
    "    X, idf = doc2vec(documents)\n",
    "\n",
    "    model = LinearSVC()\n",
    "    model.fit(X, train_labels)\n",
    "\n",
    "    # test set\n",
    "    test_files = [data[i] for i in test_idx]\n",
    "    test_labels = [labels[i] for i in test_idx]\n",
    "    _, words = wordcount(test_files)\n",
    "    documents = [[i for i in sub if i not in stop] for sub in words]\n",
    "    X_test, _ = doc2vec(documents, idf)\n",
    "\n",
    "    y_test = model.predict(X_test)\n",
    "    print(classification_report(y_test, test_labels))\n",
    "    acc.append(accuracy_score(y_test, test_labels))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy is 0.8828320830207552\n"
     ]
    }
   ],
   "source": [
    "print(f'Average Accuracy is {sum(acc)/len(acc)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
