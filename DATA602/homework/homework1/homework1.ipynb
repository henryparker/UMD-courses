{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "from random import randint\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_iniate():\n",
    "  dataset = '20_newsgroups'\n",
    "  for group in tqdm(os.listdir(dataset)):\n",
    "    filepath = os.path.join(dataset, group)\n",
    "    files = os.listdir(filepath)\n",
    "    for file in files:\n",
    "      with open(os.path.join(filepath, file), 'rb',) as f:\n",
    "          lines=f.readlines()[4:]\n",
    "  \n",
    "      folder = os.path.join('dataset', group)\n",
    "      if not os.path.exists(folder):\n",
    "          os.makedirs(folder)\n",
    "\n",
    "      with open(os.path.join(folder, file), 'wb') as f:\n",
    "          f.writelines(lines)\n",
    "\n",
    "\n",
    "def shuffle(lst):\n",
    "  temp_lst = deepcopy(lst)\n",
    "  m = len(temp_lst)\n",
    "  while (m):\n",
    "    m -= 1\n",
    "    i = randint(0, m)\n",
    "    temp_lst[m], temp_lst[i] = temp_lst[i], temp_lst[m]\n",
    "  return temp_lst\n",
    "\n",
    "def file2wordlist(filename):\n",
    "  with open(filename, 'rb') as f:\n",
    "    lines = f.readlines()\n",
    "    \n",
    "  string_lines = [line.decode('utf-8', errors='ignore').strip() for line in lines]\n",
    "  cleaned_lines = [re.sub(r'[^a-zA-Z\\s]', ' ', line.replace(\"'s\", \"\")) for line in string_lines]\n",
    "  result_string = ' '.join(cleaned_lines)\n",
    "  words = re.findall(r'\\b[a-zA-Z]+\\b', result_string)\n",
    "\n",
    "  words = list(map(lambda x: x.lower(), words))\n",
    "\n",
    "  return words\n",
    "\n",
    "def word2prob(word, wordsdict, distinctwords, laplace=1):\n",
    "    if word not in distinctwords:\n",
    "        return np.ones((len(wordsdict)))\n",
    "    prob = np.ones((len(wordsdict)))\n",
    "    for i, group in enumerate(wordsdict):\n",
    "        if word in group[1]:\n",
    "            prob[i] = (group[1][word] + laplace)/(group[0]+len(distinctwords))\n",
    "        else:\n",
    "            prob[i] = laplace/(group[0]+len(distinctwords))\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from folder 'dataset' and split into train and test\n",
    "dataset = 'dataset'\n",
    "train = []\n",
    "test = []\n",
    "\n",
    "for group in os.listdir(dataset):\n",
    "    filepath = os.path.join(dataset, group)\n",
    "    files = os.listdir(filepath)\n",
    "    files = [os.path.join(filepath, f) for f in files]\n",
    "\n",
    "    shuffle(files)\n",
    "    train = train + [files[:len(files)//2]]\n",
    "    test = test + [files[len(files)//2:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prior P\n",
    "PriorP = np.zeros(len(train))\n",
    "total = 0\n",
    "for i in range(len(train)):\n",
    "    PriorP[i] = len(train[i])\n",
    "    total += len(train[i])\n",
    "PriorP /= total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conditional P\n",
    "distinctwords = set()\n",
    "wordsdict = []\n",
    "merged_counter = Counter()\n",
    "for group in train:\n",
    "    allwords = []\n",
    "    tempdic = {}\n",
    "    for ele in group:\n",
    "        words = file2wordlist(ele)\n",
    "\n",
    "        allwords.extend(words)\n",
    "    for w in allwords:\n",
    "        if w in tempdic:\n",
    "            tempdic[w] += 1\n",
    "        else:\n",
    "            tempdic[w] = 1\n",
    "\n",
    "    distinctwords.update(allwords)\n",
    "    wordsdict.append([len(allwords), tempdic])\n",
    "    merged_counter += Counter(tempdic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set stop words\n",
    "stopwords = [ele[0] for ele in merged_counter.most_common(300)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "temwordsdic = deepcopy(wordsdict)\n",
    "temdistin = deepcopy(distinctwords)\n",
    "\n",
    "for i in range(len(temwordsdic)):\n",
    "    temwordsdic[i][1] = {k: v for k, v in temwordsdic[i][1].items() if k not in stopwords}\n",
    "temdistin = {ele for ele in temdistin if ele not in stopwords}\n",
    "\n",
    "# predict\n",
    "predictLabels = []\n",
    "trueLabels = []\n",
    "for i, group in enumerate(test):\n",
    "    for file in group:\n",
    "        words = file2wordlist(file)\n",
    "        overallsum = np.log2(PriorP)\n",
    "        for w in words:\n",
    "            prob = np.log2(word2prob(w, temwordsdic, temdistin))\n",
    "            overallsum += prob\n",
    "        predictLabels.append(np.argmax(overallsum))\n",
    "        trueLabels.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average accuracy is  0.8052805280528053\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.73      0.76       500\n",
      "           1       0.62      0.76      0.68       500\n",
      "           2       0.83      0.58      0.68       500\n",
      "           3       0.62      0.76      0.68       500\n",
      "           4       0.81      0.77      0.79       500\n",
      "           5       0.83      0.75      0.79       500\n",
      "           6       0.70      0.81      0.75       500\n",
      "           7       0.86      0.89      0.87       500\n",
      "           8       0.92      0.94      0.93       500\n",
      "           9       0.94      0.90      0.92       500\n",
      "          10       0.92      0.96      0.94       500\n",
      "          11       0.91      0.90      0.91       500\n",
      "          12       0.75      0.64      0.69       500\n",
      "          13       0.90      0.82      0.86       500\n",
      "          14       0.89      0.90      0.90       500\n",
      "          15       0.94      0.99      0.97       499\n",
      "          16       0.73      0.90      0.81       500\n",
      "          17       0.93      0.90      0.91       500\n",
      "          18       0.74      0.56      0.64       500\n",
      "          19       0.59      0.64      0.62       500\n",
      "\n",
      "    accuracy                           0.81      9999\n",
      "   macro avg       0.81      0.81      0.80      9999\n",
      "weighted avg       0.81      0.81      0.80      9999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# results\n",
    "report = classification_report(trueLabels, predictLabels)\n",
    "avg_acc = accuracy_score(trueLabels, predictLabels)\n",
    "print('average accuracy is ', avg_acc)\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
