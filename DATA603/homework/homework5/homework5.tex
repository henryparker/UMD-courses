
\documentclass[12pt]{article}
%\documentstyle[12pt]{article}
%\documentclass{amsart}
%\usepackage[dvips]{graphicx}


\usepackage{amssymb,amsmath,amscd,amsthm}
%\usepackage{graphicx,psfrag,epsfig,multirow} LINEA ORIGINAL
\usepackage{graphicx,psfrag,epsfig}


\usepackage{graphicx}
\usepackage{float}
\usepackage[active]{srcltx}

\usepackage{minted}
\usepackage{xcolor}

\newtheorem{theorem}{Theorem}[section]
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{conjecture}[theorem]{Conjecture}
\newtheorem{lemma}[theorem]{Lemma}
%\newtheorem{remark}[theorem]{Remark}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{example}[theorem]{Example}
\newtheorem{axiom}{Axiom}
\newtheorem{remark}{Remark}
\newtheorem{exercise}{Exercise}[section]

\newcommand{\thmref}[1]{Theorem~\ref{#1}}
\newcommand{\propref}[1]{Proposition~\ref{#1}}
\newcommand{\secref}[1]{\S\ref{#1}}
\newcommand{\lemref}[1]{Lemma~\ref{#1}}
\newcommand{\corref}[1]{Corollary~\ref{#1}}
\newcommand{\remref}[1]{Remark~\ref{#1}}



\setlength{\topmargin}{0mm}
\setlength{\oddsidemargin}{0mm}
\setlength{\textwidth}{160mm}
\setlength{\textheight}{215mm}
\font\bbc=msbm10 scaled 1200
\newcommand{\E}{\mathbf{E}}
\newcommand{\R}{\mbox {\bbc R}}
\newcommand{\T}{\mbox {\bbc T}}
\newcommand{\Z}{\mbox {\bbc Z}}
\def\stackunder#1#2{\mathrel{\mathop{#2}\limits_{#1}}}

\def\Area{{\rm Area}}
\def\Const{{\rm Const}}
\def\Int{{\rm Int}}

\def\eps{{\varepsilon}}

\def\EXP{\mathbb{E}}
\def\GR{\mathbb{G}}
\def\PROB{\mathbb{P}}
\def\TOR{\mathbb{T}}

\def\naturals{\mathbb{N}}

\def\brGamma{{\bar\Gamma}}
\def\brgamma{{\bar\gamma}}
\def\brtau{{\bar\tau}}
\def\brtheta{{\bar\theta}}
\def\brchi{{\bar\chi}}

\def\bI{{\bf I}}

\def\cE{\mathcal{E}}
\def\cG{\mathcal{C}}
\def\cL{\mathcal{L}}
\def\cU{\mathcal{U}}
\def\cZ{\mathcal{Z}}

\def\hN{{\hat N}}
\def\hn{{\hat n}}
\def\hy{{\hat y}}
\def\hGamma{{\hat\Gamma}}
\def\hdelta{{\hat\delta}}
\def\hsigma{{\hat\sigma}}
\def\htau{{\hat\tau}}
\def\heta{{\hat\eta}}
\def\htheta{{\hat\theta}}

\def\tW{{\tilde W}}
\def\tM{{\tilde M}}
\def\tX{{\tilde X}}
\def\tc{{\tilde c}}
\def\tp{{\tilde p}}
\def\tq{{\tilde q}}
\def\tdelta{{\tilde\delta}}
\def\teta{{\tilde\eta}}
\def\txi{{\tilde\xi}}
\def\tsigma{{\tilde\sigma}}
\def\ttheta{{\tilde\theta}}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\newminted{python}{
	linenos=true,
	bgcolor=backcolour,
	fontsize=\footnotesize,
	numbersep=5pt,
	frame=single,
	framesep=2mm
}

\title{Machine Learning Homework 5}
\author{Hairui Yin}
\date{}

\begin{document}
%\title{Exam Problems  -  Stat 400}
%\author{Winter 2008-2009}
%\normalsize Department of Mathematics\\[-4pt]
%\normalsize Princeton University\\[-4pt]
%\normalsize Princeton, NJ 08544\\[-4pt]
%\normalsize koralov@math.princeton.edu\\[-4pt]
%\date{}
\maketitle
\noindent {\bf 1.} 
\\
\textbf{(a)} Consider using a SVM to find the margin perceptron between A and B, mapping brand 'A' to $1$, brand 'B' to $-1$, we can construct the SVM given code
\begin{pythoncode}
	import pandas as pd
	import numpy as np
	from sklearn.svm import SVC
	
	df = pd.read_csv('Pizza.csv')
	
	dfAB = df[(df['brand']=='A') | (df['brand']=='B')]
	X = dfAB.iloc[:, 2:].to_numpy()
	Y = dfAB.iloc[:, 0]
	Y = Y.map({'A':1, 'B':-1})
	
	svm = SVC(kernel='linear', C=1.0, random_state=42)
\end{pythoncode}
The matrix $w^T$ and intercept $b$ are as follows:
\begin{pythoncode}
	w = svm.coef_.T
	b = svm.intercept_
\end{pythoncode}
Using this method, we can get margin perceptron seperating AB(map A to $1$, B to $-1$), seperating AC(map A to $1$, C to $-1$) and seperating BC(map B to $1$, C to $-1$), the result is as follows:
\begin{figure}[H]
	\centering
	\includegraphics[scale=0.5] {1a.png}
\end{figure}
To verify the result, we input data of brand A and B into the hyperplane of AB, then calculate $$w^Tx+b$$
\begin{pythoncode}
	X @ wAB.T + bAB
\end{pythoncode}
The picture is shown below:
\begin{figure}[H]
	\centering
	\includegraphics[scale=1.0] {1aAB.png}
\end{figure}
\noindent Similarly, the pictures using hyperplane AC, BC to classify the data are
\begin{figure}[H]
	\centering
	\includegraphics[scale=1.0] {1aAC.png}
\end{figure}
\begin{figure}[H]
	\centering
	\includegraphics[scale=1.0] {1aBC.png}
\end{figure}
\newpage
\noindent \textbf{(b)} The margins can be calculated through
$$\text{margin}=\frac{2}{||w||}$$
\begin{figure}[H]
	\centering
	\includegraphics[scale=0.5] {1b.png}
\end{figure}
\noindent \textbf{(c)} In this problem, we need three new hyperplane
$$\left\{
\begin{aligned}
\text{A vs. BC}\\
\text{B vs. AC}\\
\text{C vs. AB}\\
\end{aligned}
\right.$$
Then, we assign $x$ to label given by
$$y\in\arg\max_{j=A, B, C}w_j^Tx+b_j$$
\noindent Firstly, finding matrix $w_j$ and intercept $b_j$ is similar to q(a). The results are
\begin{figure}[H]
	\centering
	\includegraphics[scale=0.5] {1bABC.png}
\end{figure}
\noindent After than, input $s1, s2, s3$ to $\arg\max_{j=A, B, C}w_j^Tx+b_j$. These three instances are respectively labeled as
\begin{equation*}
	\left\{
	\begin{aligned}
		\text{s1}: \text{Brand C}\\
		\text{s2}: \text{Brand A}\\
		\text{s3}: \text{Brand B}\\
	\end{aligned}
	\right.
\end{equation*}
%\\
%\\

\end{document}
